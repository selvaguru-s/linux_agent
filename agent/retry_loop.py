import os
import re
from agent.command_executor import execute_shell_command
from agent.llm_client import loop_mode
from agent.result_verifier import verify_result_with_llm
from prompt_clean import clean_command_output


def extract_command_from_llm_response(response: str) -> str:
    """
    Extract the first valid-looking shell command from an LLM response.
    Ignores markdown formatting, comments, and empty lines.
    """
    # Remove markdown-style code blocks like ```bash or ```
    cleaned = re.sub(r"```(?:bash)?|```", "", response, flags=re.IGNORECASE).strip()

    for line in cleaned.splitlines():
        line = line.strip()
        if not line:
            continue  # skip empty lines
        if line.startswith("#"):
            continue  # skip comments
        if " " in line or re.match(r"^[\w\-./]+$", line):  # shell-like pattern
            return line

    return ""  # No valid command found


def loop(task: str, stdout: str, stderr: str, attempt: int = 1):
    print(f"\nğŸ” Retry Attempt {attempt} for task: {task}")

    confirm = input("â“ Do you want to retry this task using the LLM? (y/n): ").strip().lower()
    if confirm != 'y':
        print("â Retry aborted by user.")
        return

    # ğŸ§  Step 1: Build prompt for retry
    retry_prompt = f"""
You are a helpful assistant. The user initially requested this task:

TASK: {task}

The system attempted a shell command, but it did not complete the task successfully.

STDOUT from previous attempt:
{stdout}

STDERR from previous attempt:
{stderr}

This is now a RETRY stage. Please suggest a different or corrected shell command that may resolve the issue.

Respond ONLY with a shell command. No explanation, no formatting like ```bash.
"""



    # ğŸ—£ï¸ Step 2: Ask LLM for a new command
    llm_response = loop_mode(retry_prompt).strip()
    suggested_command = extract_command_from_llm_response(llm_response)
    print("Retry command",suggested_command)

    if not suggested_command:
        print("âš ï¸ Could not extract a valid shell command from the LLM response.")
        print("ğŸ” Full response was:\n", llm_response)
        return

    print(f"\nğŸ¤– Suggested Command (Attempt {attempt}):\n{suggested_command}")

    # âœ‹ Optional user confirmation before executing
    confirm_run = input("ğŸ’¬ Do you want to run this command? (y/n): ").strip().lower()
    if confirm_run != 'y':
        print("âš ï¸ Command not executed. Aborting retry.")
        return

    # ğŸ–¥ï¸ Step 3: Execute the new command
    result = execute_shell_command(suggested_command)

    # âœ… Step 4: Verify again
    if verify_result_with_llm(task, suggested_command, result["stdout"]):
        print("\nâœ… Retry Successful:\n" + result["stdout"])
    else:
        print("\nâŒ Retry Failed:\n" + (result["stdout"] or result["stderr"]))
        loop(task, result["stdout"], result["stderr"], attempt + 1)
